{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "74810457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hwb\n",
      "  Using cached hwb-0.0.15-py3-none-any.whl (8.0 kB)\n",
      "Requirement already satisfied: bezier in /opt/homebrew/lib/python3.11/site-packages (from hwb) (2021.2.12)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /opt/homebrew/lib/python3.11/site-packages (from hwb) (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/homebrew/lib/python3.11/site-packages (from opencv-python>=4.1.1->hwb) (1.24.2)\n",
      "Installing collected packages: hwb\n",
      "Successfully installed hwb-0.0.15\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python editdistance ml_collections wandb albumentations hwb\n",
    "#!BEZIER_NO_EXTENSION=true pip install bezier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf445be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import torchvision as tv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import typing as tp\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "from editdistance import eval as edit_distance\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import errno\n",
    "\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "import importlib\n",
    "import wandb\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab6f8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diploma_code.patched_hwb import HandWrittenBlot\n",
    "\n",
    "# from diploma_code.model import (\n",
    "#     ConvBlock, FusedInvertedBottleneck, ReduceBlock, Backbone, PositionalEncoding,\n",
    "#     TransformerEncoder, CTCRawDecoder, CTCDecoderModel, ParallelModel, make_single_model, make_model\n",
    "# )\n",
    "from diploma_code.model_v2 import (\n",
    "    Resnet34Backbone, BiLSTMEncoder, PositionalEncoding, TransformerEncoder, \n",
    "    CTCDecoderModel, ParallelModel, make_single_model_v2, make_model_v2\n",
    ")\n",
    "from diploma_code.transforms_torch import (\n",
    "    VerticalRandomMasking, HorizontalResizeOnly, GaussianNoise, \n",
    "    RandomHorizontalStretch, RandomChoiceN\n",
    ")\n",
    "from diploma_code.char_encoder import (\n",
    "    CharEncoder\n",
    ")\n",
    "# from diploma_code.data_loader.mjsynth import (\n",
    "#     load_mjsynth_chars, load_mjsynth_samples\n",
    "# )\n",
    "from diploma_code.dataset import (\n",
    "    BaseLTRDataset, LongLinesLTRDataset\n",
    ")\n",
    "from diploma_code.make_loader import (\n",
    "    make_char_encoder, make_datasets, make_dataloaders\n",
    ")\n",
    "from diploma_code.optimizing import (\n",
    "    pytorch_make_optimizer, StepLRWithWarmup, make_lr_scheduler\n",
    ")\n",
    "from diploma_code.utils import (\n",
    "    log_metric_wandb, batch_to_device\n",
    ")\n",
    "from diploma_code.evaluation import (\n",
    "    my_ctc_loss, my_dml_loss, decode_ocr_probs, get_edit_distance, \n",
    "    EpochValueProcessor, EpochDMLProcessor, CERProcessor\n",
    ")\n",
    "from diploma_code.trainer import (\n",
    "    LTRTrainer\n",
    ")\n",
    "\n",
    "from diploma_code.config import default_diploma_config, get_config\n",
    "\n",
    "from diploma_code.configs import BaseDatasetConfig\n",
    "from diploma_code.configs import IamConfig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0718f459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'diploma_code.configs' from '/Users/d.mokeev/MIPT/mutual_htr/diploma_code/configs/__init__.py'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import diploma_code\n",
    "import diploma_code.data_loader\n",
    "\n",
    "importlib.reload(diploma_code.char_encoder)\n",
    "\n",
    "importlib.reload(diploma_code.config)\n",
    "importlib.reload(diploma_code.dataset)\n",
    "\n",
    "importlib.reload(diploma_code.data_loader)\n",
    "importlib.reload(diploma_code.evaluation)\n",
    "\n",
    "importlib.reload(diploma_code.optimizing)\n",
    "\n",
    "importlib.reload(diploma_code.model_v2)\n",
    "importlib.reload(diploma_code.utils)\n",
    "importlib.reload(diploma_code.trainer)\n",
    "\n",
    "importlib.reload(diploma_code.make_loader)\n",
    "importlib.reload(diploma_code.make_transforms)\n",
    "\n",
    "importlib.reload(diploma_code.transforms_functional)\n",
    "\n",
    "importlib.reload(diploma_code.configs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a1d43e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a9894117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 ./train.py  --config=./diploma_code/config.py --config.wandb.run_name='sad_dogo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06a74e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_config()\n",
    "cfg.training.eval_epochs_interval = 1\n",
    "cfg.training.eval_test_interval = 3\n",
    "cfg.training.snapshot_epochs_interval = 3\n",
    "cfg.data.root_path = './diploma_code/prepare_data/prepared_datasets/'\n",
    "cfg.data.iam.path = './diploma_code/prepare_data/prepared_datasets/'\n",
    "\n",
    "cfg.training.loader_num_workers = 1\n",
    "cfg.evaluate.loader_num_workers = 1\n",
    "\n",
    "cfg.device = 'cpu'\n",
    "\n",
    "# cfg.training.load_from_checkpoint = True\n",
    "# cfg.wandb.resume = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5b7f65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickle_trick(obj, max_depth=10):\n",
    "    output = {}\n",
    "\n",
    "    if max_depth <= 0:\n",
    "        return output\n",
    "\n",
    "    try:\n",
    "        pickle.dumps(obj)\n",
    "    except (pickle.PicklingError, TypeError) as e:\n",
    "        failing_children = []\n",
    "\n",
    "        if hasattr(obj, \"__dict__\"):\n",
    "            for k, v in obj.__dict__.items():\n",
    "                result = pickle_trick(v, max_depth=max_depth - 1)\n",
    "                if result:\n",
    "                    failing_children.append(result)\n",
    "\n",
    "        output = {\n",
    "            \"fail\": obj, \n",
    "            \"err\": e, \n",
    "            \"depth\": max_depth, \n",
    "            \"failing_children\": failing_children\n",
    "        }\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be4edb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltr = LTRTrainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9cc534f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ncxel13y) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9b1e1b3b3f41468184dbb7605700bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cpu_looser</strong> at: <a href='https://wandb.ai/kafka_zhuk/diploma_dml/runs/ncxel13y' target=\"_blank\">https://wandb.ai/kafka_zhuk/diploma_dml/runs/ncxel13y</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230514_075809-ncxel13y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ncxel13y). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0055d39999c84fdaa05399680597c1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016768231250171083, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/d.mokeev/MIPT/mutual_htr/wandb/run-20230514_080051-9unhgs6u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kafka_zhuk/diploma_dml/runs/9unhgs6u' target=\"_blank\">cpu_looser</a></strong> to <a href='https://wandb.ai/kafka_zhuk/diploma_dml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kafka_zhuk/diploma_dml' target=\"_blank\">https://wandb.ai/kafka_zhuk/diploma_dml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kafka_zhuk/diploma_dml/runs/9unhgs6u' target=\"_blank\">https://wandb.ai/kafka_zhuk/diploma_dml/runs/9unhgs6u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                               | 2/1207 [00:34<5:49:14, 17.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mltr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu_looser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MIPT/mutual_htr/diploma_code/trainer.py:203\u001b[0m, in \u001b[0;36mLTRTrainer.train\u001b[0;34m(self, run_name)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mnum_epochs:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(loader):\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    206\u001b[0m         batch \u001b[38;5;241m=\u001b[39m batch_to_device(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:256\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:423\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 423\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:930\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    927\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 930\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ltr.train('cpu_looser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd79951a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/lehahel/dmdiploma/wandb/run-20230512_223701-6rm0zgo4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kafka_zhuk/diploma_dml/runs/6rm0zgo4' target=\"_blank\">sad_dogo</a></strong> to <a href='https://wandb.ai/kafka_zhuk/diploma_dml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kafka_zhuk/diploma_dml' target=\"_blank\">https://wandb.ai/kafka_zhuk/diploma_dml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kafka_zhuk/diploma_dml/runs/6rm0zgo4' target=\"_blank\">https://wandb.ai/kafka_zhuk/diploma_dml/runs/6rm0zgo4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:20<00:00, 16.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:15<00:00,  8.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:18<00:00, 16.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:14<00:00,  8.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:18<00:00, 16.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 365/365 [00:50<00:00,  7.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:18<00:00, 16.37it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:17<00:00,  7.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:18<00:00, 16.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:17<00:00, 16.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 365/365 [00:52<00:00,  6.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:18<00:00, 16.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:17<00:00,  6.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:18<00:00, 16.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:20<00:00, 16.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 365/365 [00:54<00:00,  6.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:18<00:00, 16.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:18<00:00, 16.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:17<00:00, 16.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:19<00:00,  6.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 365/365 [00:53<00:00,  6.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:17<00:00, 16.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:19<00:00, 16.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:18<00:00, 16.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 365/365 [00:54<00:00,  6.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:19<00:00, 16.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:19<00:00, 16.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:19<00:00, 16.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 365/365 [00:52<00:00,  6.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:18<00:00, 16.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:17<00:00, 16.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 3241/3241 [03:19<00:00, 16.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 122/122 [00:18<00:00,  6.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 365/365 [00:52<00:00,  6.94it/s]\n",
      "  4%|██▊                                                                             | 114/3241 [00:07<03:30, 14.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mltr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msad_dogo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dmdiploma/diploma_code/trainer.py:231\u001b[0m, in \u001b[0;36mLTRTrainer.train\u001b[0;34m(self, run_name)\u001b[0m\n\u001b[1;32m    227\u001b[0m result_loss \u001b[38;5;241m=\u001b[39m criterion_processor(loss, gt_text\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_inf_or_nan_loss(result_loss, batch, log_probs, inp_len)\n\u001b[0;32m--> 231\u001b[0m \u001b[43mresult_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m grads \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    234\u001b[0m     param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters()\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    237\u001b[0m ]\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(grads) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/dmdiploma/miniconda3/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dmdiploma/miniconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ltr.train('sad_dogo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c53435b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/1696/4/211_Queened_61779.jpg has premature end of jpeg file\n",
      "Checked 100000 images in 18.951529502868652 seconds, found 1 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/2540/4/246_SQUAMOUS_73902.jpg has premature end of jpeg file\n",
      "Checked 200000 images in 37.68372654914856 seconds, found 2 corrupted\n",
      "Checked 300000 images in 56.298471212387085 seconds, found 2 corrupted\n",
      "Checked 400000 images in 75.03809976577759 seconds, found 2 corrupted\n",
      "Checked 500000 images in 93.85237288475037 seconds, found 2 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/2489/4/221_snored_72290.jpg has premature end of jpeg file\n",
      "Checked 600000 images in 112.51990985870361 seconds, found 3 corrupted\n",
      "Checked 700000 images in 131.21052145957947 seconds, found 3 corrupted\n",
      "Checked 800000 images in 150.05990934371948 seconds, found 3 corrupted\n",
      "Checked 900000 images in 168.71192383766174 seconds, found 3 corrupted\n",
      "Checked 1000000 images in 187.46954560279846 seconds, found 3 corrupted\n",
      "Checked 1100000 images in 206.4558708667755 seconds, found 3 corrupted\n",
      "Checked 1200000 images in 225.24797892570496 seconds, found 3 corrupted\n",
      "Checked 1300000 images in 244.03781819343567 seconds, found 3 corrupted\n",
      "failed to process file data/mjsynth/mnt/ramdisk/max/90kDICT32px/2911/6/77_heretical_35885.jpg, error: [Errno 22] Invalid argument\n",
      "Checked 1400000 images in 263.0574812889099 seconds, found 4 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/495/6/81_MIDYEAR_48332.jpg has premature end of jpeg file\n",
      "Checked 1500000 images in 282.23429775238037 seconds, found 5 corrupted\n",
      "Checked 1600000 images in 301.77506279945374 seconds, found 5 corrupted\n",
      "Checked 1700000 images in 321.3719696998596 seconds, found 5 corrupted\n",
      "Checked 1800000 images in 340.912540435791 seconds, found 5 corrupted\n",
      "Checked 1900000 images in 360.401948928833 seconds, found 5 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/264/2/362_FORETASTE_30276.jpg has premature end of jpeg file\n",
      "failed to process file data/mjsynth/mnt/ramdisk/max/90kDICT32px/2852/6/60_TOILSOME_79481.jpg, error: [Errno 22] Invalid argument\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/1730/2/361_HEREON_35880.jpg has premature end of jpeg file\n",
      "Checked 2000000 images in 379.8093194961548 seconds, found 8 corrupted\n",
      "Checked 2100000 images in 399.1607177257538 seconds, found 8 corrupted\n",
      "Checked 2200000 images in 418.5676634311676 seconds, found 8 corrupted\n",
      "Checked 2300000 images in 438.09797835350037 seconds, found 8 corrupted\n",
      "Checked 2400000 images in 457.4621205329895 seconds, found 8 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/554/2/366_Teleconferences_77948.jpg has premature end of jpeg file\n",
      "Checked 2500000 images in 476.85496854782104 seconds, found 9 corrupted\n",
      "Checked 2600000 images in 496.25917887687683 seconds, found 9 corrupted\n",
      "Checked 2700000 images in 515.9029455184937 seconds, found 9 corrupted\n",
      "Checked 2800000 images in 535.1907196044922 seconds, found 9 corrupted\n",
      "Checked 2900000 images in 554.5571353435516 seconds, found 9 corrupted\n",
      "Checked 3000000 images in 573.9729766845703 seconds, found 9 corrupted\n",
      "Checked 3100000 images in 593.3871314525604 seconds, found 9 corrupted\n",
      "Checked 3200000 images in 612.675607919693 seconds, found 9 corrupted\n",
      "Checked 3300000 images in 632.0768239498138 seconds, found 9 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/1332/4/224_TETHERED_78397.jpg has premature end of jpeg file\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/627/6/83_PATRIARCHATE_55931.jpg has premature end of jpeg file\n",
      "Checked 3400000 images in 651.5288732051849 seconds, found 11 corrupted\n",
      "Checked 3500000 images in 670.931713104248 seconds, found 11 corrupted\n",
      "Checked 3600000 images in 690.5575475692749 seconds, found 11 corrupted\n",
      "Checked 3700000 images in 710.1907341480255 seconds, found 11 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/275/6/96_hackle_34465.jpg has premature end of jpeg file\n",
      "Checked 3800000 images in 729.52659034729 seconds, found 12 corrupted\n",
      "Checked 3900000 images in 748.8728542327881 seconds, found 12 corrupted\n",
      "failed to process file data/mjsynth/mnt/ramdisk/max/90kDICT32px/2069/4/192_whittier_86389.jpg, error: [Errno 22] Invalid argument\n",
      "Checked 4000000 images in 768.2088203430176 seconds, found 13 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/1881/4/225_Marbling_46673.jpg has premature end of jpeg file\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/936/2/375_LOCALITIES_44992.jpg has premature end of jpeg file\n",
      "Checked 4100000 images in 787.7751998901367 seconds, found 15 corrupted\n",
      "Checked 4200000 images in 807.0151362419128 seconds, found 15 corrupted\n",
      "Checked 4300000 images in 826.3629400730133 seconds, found 15 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/2749/6/101_Chided_13155.jpg has premature end of jpeg file\n",
      "Checked 4400000 images in 845.7661924362183 seconds, found 16 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/429/4/208_Mainmasts_46140.jpg has premature end of jpeg file\n",
      "Checked 4500000 images in 865.1481721401215 seconds, found 17 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/869/4/234_TRIASSIC_80582.jpg has premature end of jpeg file\n",
      "Checked 4600000 images in 884.3753561973572 seconds, found 18 corrupted\n",
      "Checked 4700000 images in 903.6393489837646 seconds, found 18 corrupted\n",
      "Checked 4800000 images in 923.1511425971985 seconds, found 18 corrupted\n",
      "Checked 4900000 images in 942.6447267532349 seconds, found 18 corrupted\n",
      "Checked 5000000 images in 961.8419733047485 seconds, found 18 corrupted\n",
      "Checked 5100000 images in 981.1611807346344 seconds, found 18 corrupted\n",
      "Checked 5200000 images in 1000.552271604538 seconds, found 18 corrupted\n",
      "Checked 5300000 images in 1019.9057981967926 seconds, found 18 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/2557/2/351_DOWN_23492.jpg has premature end of jpeg file\n",
      "Checked 5400000 images in 1039.1831986904144 seconds, found 19 corrupted\n",
      "Checked 5500000 images in 1058.5144839286804 seconds, found 19 corrupted\n",
      "Checked 5600000 images in 1077.7919263839722 seconds, found 19 corrupted\n",
      "Checked 5700000 images in 1097.1177341938019 seconds, found 19 corrupted\n",
      "Checked 5800000 images in 1116.4663891792297 seconds, found 19 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/2128/2/369_REDACTED_63458.jpg has premature end of jpeg file\n",
      "Checked 5900000 images in 1135.9374918937683 seconds, found 20 corrupted\n",
      "failed to process file data/mjsynth/mnt/ramdisk/max/90kDICT32px/173/2/358_BURROWING_10395.jpg, error: [Errno 22] Invalid argument\n",
      "Checked 6000000 images in 1155.5433979034424 seconds, found 21 corrupted\n",
      "Checked 6100000 images in 1175.2199811935425 seconds, found 21 corrupted\n",
      "Checked 6200000 images in 1194.8283450603485 seconds, found 21 corrupted\n",
      "failed to process file data/mjsynth/mnt/ramdisk/max/90kDICT32px/368/4/232_friar_30876.jpg, error: [Errno 22] Invalid argument\n",
      "Checked 6300000 images in 1214.5452663898468 seconds, found 22 corrupted\n",
      "Checked 6400000 images in 1234.187614440918 seconds, found 22 corrupted\n",
      "Checked 6500000 images in 1253.5740842819214 seconds, found 22 corrupted\n",
      "Checked 6600000 images in 1272.8712656497955 seconds, found 22 corrupted\n",
      "Checked 6700000 images in 1292.0920703411102 seconds, found 22 corrupted\n",
      "Checked 6800000 images in 1311.4273085594177 seconds, found 22 corrupted\n",
      "Checked 6900000 images in 1330.7157838344574 seconds, found 22 corrupted\n",
      "Checked 7000000 images in 1350.047779083252 seconds, found 22 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/596/2/372_Ump_81662.jpg has premature end of jpeg file\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/1863/4/223_Diligently_21672.jpg has premature end of jpeg file\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/2194/2/334_EFFLORESCENT_24742.jpg has premature end of jpeg file\n",
      "Checked 7100000 images in 1369.3294756412506 seconds, found 25 corrupted\n",
      "Checked 7200000 images in 1388.5914645195007 seconds, found 25 corrupted\n",
      "failed to process file data/mjsynth/mnt/ramdisk/max/90kDICT32px/2025/2/364_SNORTERS_72304.jpg, error: [Errno 22] Invalid argument\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/1650/2/355_stony_74902.jpg has premature end of jpeg file\n",
      "Checked 7300000 images in 1407.951684474945 seconds, found 27 corrupted\n",
      "Checked 7400000 images in 1427.4152908325195 seconds, found 27 corrupted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 7500000 images in 1446.9203684329987 seconds, found 27 corrupted\n",
      "failed to process file data/mjsynth/mnt/ramdisk/max/90kDICT32px/913/4/231_randoms_62372.jpg, error: [Errno 22] Invalid argument\n",
      "Checked 7600000 images in 1466.345933675766 seconds, found 28 corrupted\n",
      "Checked 7700000 images in 1485.691297531128 seconds, found 28 corrupted\n",
      "Checked 7800000 images in 1504.955777645111 seconds, found 28 corrupted\n",
      "Checked 7900000 images in 1524.2437522411346 seconds, found 28 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/384/4/220_bolts_8596.jpg has premature end of jpeg file\n",
      "failed to process file data/mjsynth/mnt/ramdisk/max/90kDICT32px/1817/2/363_actuating_904.jpg, error: [Errno 22] Invalid argument\n",
      "Checked 8000000 images in 1543.4584033489227 seconds, found 30 corrupted\n",
      "Checked 8100000 images in 1562.727600812912 seconds, found 30 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/905/4/234_Postscripts_59142.jpg has premature end of jpeg file\n",
      "Checked 8200000 images in 1582.0282554626465 seconds, found 31 corrupted\n",
      "Checked 8300000 images in 1601.2372965812683 seconds, found 31 corrupted\n",
      "Checked 8400000 images in 1620.612556695938 seconds, found 31 corrupted\n",
      "Checked 8500000 images in 1639.9000358581543 seconds, found 31 corrupted\n",
      "Checked 8600000 images in 1659.2211124897003 seconds, found 31 corrupted\n",
      "data/mjsynth/mnt/ramdisk/max/90kDICT32px/2013/2/370_refract_63890.jpg has premature end of jpeg file\n",
      "Checked 8700000 images in 1678.6087620258331 seconds, found 32 corrupted\n",
      "Checked 8800000 images in 1697.6653468608856 seconds, found 32 corrupted\n",
      "Checked 8900000 images in 1716.8307662010193 seconds, found 32 corrupted\n"
     ]
    }
   ],
   "source": [
    "path = \"data/mjsynth/mnt/ramdisk/max/90kDICT32px\"\n",
    "\n",
    "bad_files = []\n",
    "\n",
    "import time\n",
    "\n",
    "count = 0\n",
    "begin = time.time()\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        if filename.split('.')[-1] == 'jpg':\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "            with open(full_path, 'rb') as im:\n",
    "                try:\n",
    "                    im.seek(-2,2)\n",
    "                except OSError as e:\n",
    "                    print(f'failed to process file {full_path}, error: {e}')\n",
    "                    bad_files.append(full_path)\n",
    "                    continue\n",
    "                if im.read() != b'\\xff\\xd9':\n",
    "                    print(f'{full_path} has premature end of jpeg file')\n",
    "                    bad_files.append(full_path)\n",
    "                    continue\n",
    "            val = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if val is None:\n",
    "                print(f'{full_path} has a corrupted image')\n",
    "                bad_files.append(full_path)\n",
    "            count += 1\n",
    "            if count % 100000 == 0:\n",
    "                print(f'Checked {count} images in {time.time() - begin} seconds, found {len(bad_files)} corrupted')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88514f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
